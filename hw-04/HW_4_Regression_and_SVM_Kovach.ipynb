{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Assignment #4 (Individual)\n",
    "## Regression and SVM Predictive Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"text-align: right;\"> &#9989; Ella Kovach.</p>\n",
    "### <p style=\"text-align: right;\"> &#9989; kovachel.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal for this homework assignment\n",
    "By now, you have learned a bit about predictive models. In this assignment, you will practice:\n",
    "\n",
    "* Building predictive models using `statsmodels` and `sklearn`\n",
    "* Evaluating your predictive models\n",
    "\n",
    "**This assignment is due roughly two weeks from now at 11:59 pm on Friday, April 21st.** It should be uploaded into the \"Homework Assignments\" submission folder for Homework #4.  Submission instructions can be found at the end of the notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 0: Add to your Git repository to track your progress on your assignment (4 points)\n",
    "\n",
    "For this assignment, you're going to add it to the `cmse202-s23-turnin` repository you created in class so that you can track your progress on the assignment and preserve the final version that you turn in. In order to do this you need to\n",
    "\n",
    "**&#9989; Do the following**:\n",
    "\n",
    "1. Navigate to your `cmse202-s23-turnin` repository and create a new directory called `hw-04`.\n",
    "2. Move this notebook into that **new directory** in your repository, then **add it and commit it to your repository**.\n",
    "1. Finally, to test that everything is working, \"git push\" the file so that it ends up in your GitHub repository.\n",
    "\n",
    "**Important**: Double check you've added your Professor and your TA as collaborators to your \"turnin\" repository (you should have done this in the previous homework assignment).\n",
    "\n",
    "**Also important**: Make sure that the version of this notebook that you are working on is the same one that you just added to your repository! If you are working on a different copy of the notebook, **none of your changes will be tracked**!\n",
    "\n",
    "If everything went as intended, the file should now show up on your GitHub account in the \"`cmse202-s23-turnin`\" repository inside the `hw-04` directory that you just created.  Periodically, **you'll be asked to commit your changes to the repository and push them to the remote GitHub location**. Of course, you can always commit your changes more often than that, if you wish.  It can be good to get into a habit of committing your changes any time you make a significant modification, or when you stop working on the project for a bit.\n",
    "\n",
    "&#9989; **Do this**: Before you move on, put the command that your instructor should run to clone your repository in the markdown cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "git clone https://github.com/kovachel/cmse202-s23-turnin-Kovach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.integrate import solve_ivp\n",
    "import seaborn as sns\n",
    "from PIL import Image \n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "import matplotlib.pylab as plt\n",
    "from ipywidgets import interact\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Model to Predict if it Will Rain Tomorrow\n",
    "\n",
    "In this dataset we have weather data for a number of Australian cities. We’re going to **build a model that uses data from today to predict if it will rain tomorrow.** To simplify our model, let’s just look at the weather for one city.\n",
    "\n",
    "## Part 1. Working with the Data\n",
    "\n",
    "The dataset that we’ll be using can be found here:\n",
    "- `https://raw.githubusercontent.com/msu-cmse-courses/cmse202-S23-data/main/HW/HW4/aussie_weather_data.csv`\n",
    "\n",
    "#### 1.1 (3 Points)\n",
    "**Download the data set and read it in using Pandas.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code here\n",
    "data = pd.read_csv(\"aussie_weather_data.csv\", delimiter=',', skiprows=0, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 (3 Points)\n",
    "This dataset has weather information for multiple cities in Australia. It’s quite a large dataset. In fact, it’s a little *too* large for our purposes; it will take a considerable amount of time to train a model on so much data. So we’ll just work with the data for a specific city.\n",
    "\n",
    "The first thing we’ll do is see which cities we have data for. \n",
    "**Print out a list of the specific cities in this dataset.** (Note that this is not the same as printing the entire `Location` column.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NorfolkIsland' 'SydneyAirport' 'WaggaWagga' 'MelbourneAirport' 'Mildura'\n",
      " 'Watsonia' 'Brisbane' 'Cairns' 'Townsville' 'MountGambier' 'Nuriootpa'\n",
      " 'PerthAirport' 'Perth' 'AliceSprings' 'Darwin']\n"
     ]
    }
   ],
   "source": [
    "#Write your code here\n",
    "cities = data[\"Location\"].unique()\n",
    "print(cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 (3 Points)\n",
    "Select one of the cities (and **please** don't just pick the first one!). Cut down your dataframe so that it only contains data from your chosen city. You should also **look through the columns in this dataset and ensure that all of the data is ready for our analysis/model creation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code here\n",
    "Darwin = data[\"Location\"]==\"Darwin\"\n",
    "darwins = data[Darwin]\n",
    "darwin = darwins.drop([\"Location\"], axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 (3 Points)\n",
    "Finally, before we start creating our models, let's first split our data into training and testing datasets. **Keep in mind what we want our model to predict and how this dataset gives you the information you need for your model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayOfMonth</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36453</th>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>33.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>...</td>\n",
       "      <td>81.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>1012.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.4</td>\n",
       "      <td>32.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36454</th>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>19.4</td>\n",
       "      <td>32.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>22.5</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>81.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1016.8</td>\n",
       "      <td>1012.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>31.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36455</th>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>18.2</td>\n",
       "      <td>31.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1017.2</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>31.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36456</th>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>17.3</td>\n",
       "      <td>30.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.3</td>\n",
       "      <td>1013.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>29.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36457</th>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>15.5</td>\n",
       "      <td>30.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>337.5</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1016.3</td>\n",
       "      <td>1012.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.2</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39510</th>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>19.3</td>\n",
       "      <td>33.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>63.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1013.9</td>\n",
       "      <td>1010.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39511</th>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>21.2</td>\n",
       "      <td>32.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>8.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>56.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1014.6</td>\n",
       "      <td>1011.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.8</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39512</th>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>20.7</td>\n",
       "      <td>32.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>...</td>\n",
       "      <td>46.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1015.3</td>\n",
       "      <td>1011.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.8</td>\n",
       "      <td>32.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39513</th>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>19.5</td>\n",
       "      <td>31.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>10.6</td>\n",
       "      <td>337.5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1014.9</td>\n",
       "      <td>1010.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.8</td>\n",
       "      <td>29.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39514</th>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>20.2</td>\n",
       "      <td>31.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>10.7</td>\n",
       "      <td>22.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1013.9</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.4</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3062 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year  Month  DayOfMonth  MinTemp  MaxTemp  Rainfall  Evaporation  \\\n",
       "36453  2008      7           1     20.0     33.1       0.0          4.4   \n",
       "36454  2008      7           2     19.4     32.4       0.0          6.0   \n",
       "36455  2008      7           3     18.2     31.8       0.0          8.0   \n",
       "36456  2008      7           4     17.3     30.7       0.0          7.0   \n",
       "36457  2008      7           5     15.5     30.8       0.0          7.0   \n",
       "...     ...    ...         ...      ...      ...       ...          ...   \n",
       "39510  2017      6          20     19.3     33.4       0.0          6.0   \n",
       "39511  2017      6          21     21.2     32.6       0.0          7.6   \n",
       "39512  2017      6          22     20.7     32.8       0.0          5.6   \n",
       "39513  2017      6          23     19.5     31.8       0.0          6.2   \n",
       "39514  2017      6          24     20.2     31.7       0.0          5.6   \n",
       "\n",
       "       Sunshine  WindGustDir  WindGustSpeed  ...  Humidity9am  Humidity3pm  \\\n",
       "36453      11.0          0.0           41.0  ...         81.0         32.0   \n",
       "36454      10.4         22.5           50.0  ...         81.0         17.0   \n",
       "36455      11.0          0.0           46.0  ...         38.0         24.0   \n",
       "36456      10.4          0.0           44.0  ...         55.0         16.0   \n",
       "36457      10.8        337.5           46.0  ...         37.0         16.0   \n",
       "...         ...          ...            ...  ...          ...          ...   \n",
       "39510      11.0         22.5           35.0  ...         63.0         32.0   \n",
       "39511       8.6          0.0           37.0  ...         56.0         28.0   \n",
       "39512      11.0          0.0           33.0  ...         46.0         23.0   \n",
       "39513      10.6        337.5           26.0  ...         62.0         58.0   \n",
       "39514      10.7         22.5           30.0  ...         73.0         32.0   \n",
       "\n",
       "       Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  \\\n",
       "36453       1016.0       1012.1       1.0       2.0     25.4     32.3   \n",
       "36454       1016.8       1012.4       1.0       1.0     24.3     31.9   \n",
       "36455       1017.2       1013.0       0.0       1.0     24.3     31.2   \n",
       "36456       1017.3       1013.6       2.0       6.0     21.3     29.8   \n",
       "36457       1016.3       1012.6       1.0       1.0     22.2     29.6   \n",
       "...            ...          ...       ...       ...      ...      ...   \n",
       "39510       1013.9       1010.5       0.0       1.0     24.5     32.3   \n",
       "39511       1014.6       1011.2       7.0       0.0     24.8     32.0   \n",
       "39512       1015.3       1011.8       0.0       0.0     24.8     32.1   \n",
       "39513       1014.9       1010.7       1.0       1.0     24.8     29.2   \n",
       "39514       1013.9       1009.7       6.0       5.0     25.4     31.0   \n",
       "\n",
       "       RainToday  RainTomorrow  \n",
       "36453          0             0  \n",
       "36454          0             0  \n",
       "36455          0             0  \n",
       "36456          0             0  \n",
       "36457          0             0  \n",
       "...          ...           ...  \n",
       "39510          0             0  \n",
       "39511          0             0  \n",
       "39512          0             0  \n",
       "39513          0             0  \n",
       "39514          0             0  \n",
       "\n",
       "[3062 rows x 24 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = darwin.drop('RainTomorrow', axis = 1)\n",
    "y = darwin['RainTomorrow']\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(x,y, test_size = 0.3, random_state = 21)\n",
    "darwin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Building a Regression Model\n",
    "\n",
    "#### 2.1 (3 Points)\n",
    "We’ll start by creating a regression model. **Does it make sense for us to use linear regression or logistic regression? Explain your choice.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*I am going to go with a logistic regression. I think it would be beneficial to see the correlation and relevance of rainfall to each variable in the data set. It will allow us to see what parameters are the most statistically significant in the model. Also since the question is more of a yes or no question logistic regression would be more applicable.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 (12 Points)\n",
    "Create a regression model. Use the model summary to determine which parameters are most statistically significant in your model. If you get an error during at this stage it may be helpful to go back to part 1.3 and ensure that all of your data is appropriate for creating a model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.275494\n",
      "         Iterations 9\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           RainTomorrow   No. Observations:                 2143\n",
      "Model:                          Logit   Df Residuals:                     2119\n",
      "Method:                           MLE   Df Model:                           23\n",
      "Date:                Sat, 22 Apr 2023   Pseudo R-squ.:                  0.5192\n",
      "Time:                        14:32:48   Log-Likelihood:                -590.38\n",
      "converged:                       True   LL-Null:                       -1227.9\n",
      "Covariance Type:            nonrobust   LLR p-value:                3.313e-255\n",
      "=================================================================================\n",
      "                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const           188.3213     68.670      2.742      0.006      53.731     322.911\n",
      "Year             -0.0220      0.029     -0.762      0.446      -0.079       0.035\n",
      "Month            -0.0274      0.021     -1.280      0.201      -0.069       0.015\n",
      "DayOfMonth        0.0044      0.009      0.521      0.603      -0.012       0.021\n",
      "MinTemp          -0.0473      0.079     -0.599      0.549      -0.202       0.108\n",
      "MaxTemp           0.1035      0.095      1.083      0.279      -0.084       0.291\n",
      "Rainfall          0.0088      0.008      1.070      0.284      -0.007       0.025\n",
      "Evaporation      -0.0743      0.046     -1.631      0.103      -0.164       0.015\n",
      "Sunshine         -0.2154      0.043     -5.009      0.000      -0.300      -0.131\n",
      "WindGustDir       0.0003      0.001      0.398      0.691      -0.001       0.002\n",
      "WindGustSpeed     0.0935      0.009      9.958      0.000       0.075       0.112\n",
      "WindDir9am       -0.0007      0.001     -1.047      0.295      -0.002       0.001\n",
      "WindDir3pm       -0.0019      0.001     -1.424      0.154      -0.005       0.001\n",
      "WindSpeed9am     -0.0246      0.015     -1.653      0.098      -0.054       0.005\n",
      "WindSpeed3pm     -0.0366      0.014     -2.592      0.010      -0.064      -0.009\n",
      "Humidity9am       0.0010      0.016      0.063      0.949      -0.030       0.032\n",
      "Humidity3pm       0.1041      0.015      6.900      0.000       0.075       0.134\n",
      "Pressure9am       0.4708      0.121      3.879      0.000       0.233       0.709\n",
      "Pressure3pm      -0.6353      0.131     -4.859      0.000      -0.892      -0.379\n",
      "Cloud9am         -0.0978      0.054     -1.816      0.069      -0.203       0.008\n",
      "Cloud3pm          0.1394      0.056      2.476      0.013       0.029       0.250\n",
      "Temp9am           0.2304      0.094      2.463      0.014       0.047       0.414\n",
      "Temp3pm           0.1146      0.090      1.273      0.203      -0.062       0.291\n",
      "RainToday        -0.0200      0.214     -0.093      0.926      -0.439       0.399\n",
      "=================================================================================\n"
     ]
    }
   ],
   "source": [
    "#Write your code here\n",
    "logit_model = sm.Logit(train_labels, sm.add_constant(train_data))\n",
    "result = logit_model.fit()\n",
    "print(result.summary() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A few of the statistically significant features consist of Year, Mintemp, Evaporation, Sunshine, RainToday.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 (8 Points)\n",
    "**Fit your test data and create/print a confusion matrix. We’ll use this to evaluate how well your predicitve model performs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerun_training = True\n",
    "filename = 'full_face_model.p'\n",
    "tmp_vectors = train_data\n",
    "tmp_labels = train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91       687\n",
      "           1       0.78      0.60      0.68       232\n",
      "\n",
      "    accuracy                           0.86       919\n",
      "   macro avg       0.83      0.77      0.79       919\n",
      "weighted avg       0.85      0.86      0.85       919\n",
      "\n",
      "[[647  40]\n",
      " [ 92 140]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_vectors = sm.add_constant(test_data)\n",
    "true_labels = test_labels\n",
    "\n",
    "pred_labels = np.round(result.predict(predict_vectors))\n",
    "\n",
    "cm = confusion_matrix(true_labels, pred_labels)\n",
    "\n",
    "print(classification_report(true_labels, pred_labels))\n",
    "print(confusion_matrix(true_labels, pred_labels))\n",
    "\n",
    "CM = metrics.ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = [True, False])\n",
    "CM.plot()\n",
    "plt.title(\"Confusion Matrix for Rain Prediciton\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 (3 Points)\n",
    "Look at/calculate the Precision and Recall of your model. **Which one is greater? Describe in plain language what that means about the performance of your model (I.e., the circumstances in which it does/doesn’t do well).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Precision how often it is predicted posivite and is right. Recall the ratio of true positives to the sum of true positives and false negatives. Precision appears to be greater when the model is predicting it won't rain. Where as Recall is greater when the model is predicting it will rain.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Interlude: A Base Rate Frequency Model (12 Points)\n",
    "\n",
    "If we didn't create a fancy model for predicting future rainfall, would that mean that we had *no way* of predicting if it would rain? Of course not. There's always *some* kind of model we can use (they just won't be very sophisticated). \n",
    "\n",
    "In the case of our problem--predicting whether it will rain tomorrow--what is the simplest model we could use? We'd need to look at the **base rate frequency**. If we know that, over the course of the year, it rains ~30% of the time, that would be our base rate frequency. If we were to guess that it would be sunny every day of the year, we'd be wrong ~30% of the time, *but we'd be right ~70% of the time.* \n",
    "\n",
    "Why is this important? Imagine we create a sophisticated model that accurately predicts rain/no rain ~60% of the time; without any other information, we might think, \"That's not too bad, I guess.\" It certainly feels better than *no* information, right? Now think about the base rate frequency model, which achieves an accuracy of **70%** just by guessing the same thing every time. Suddenly, our sophisticated model seems like crap! It tells us we could be doing ~10% better than our fancy model by guessing. This is why we use the base rate frequency as a simple way to test our models.\n",
    "\n",
    "\n",
    "**Calculate how frequently it rains in your city. If you were to guess that it *wasn't* going to rain every day, how frequently would you be right? (We'll use this as our baseline model.)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7423252775963423\n"
     ]
    }
   ],
   "source": [
    "#Write your code for calculating the frequency of rain here.\n",
    "rains = darwin[\"RainTomorrow\"] == 1\n",
    "rainy_days = rains.sum()\n",
    "days = len(darwin.index)\n",
    "\n",
    "Frequency = 1 - rainy_days/days\n",
    "print(Frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*It would be right 74.2% of the time.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### &#128721; STOP (3 Point)\n",
    "**Pause to commit your changes to your Git repository!**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository with a meaningful commit message.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 SVM Model\n",
    "\n",
    "We’ve seen how regression faired in predicting rain; now let’s give Support Vector Machines a shot. \n",
    "\n",
    "It’s not clear, *a priori*, which type of kernel (linear or RBF) would fair better. Therefore, we’ll need to test out both kernel types, as well as multiple values for hyperparameters ($C$ and $\\gamma$). \n",
    "\n",
    "#### 4.1 (12 Points)\n",
    "Run a grid search over both types of kernels and multiple values of $C$ and $\\gamma$ (we recommend [0.01,0.1,1.0,10.0] for both). We *STRONGLY* recommend you set the parameter `n_jobs=-1` in `GridSearchCV`, which will distribute the computational load. Make sure to write down your best-fit hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the classifier to the training set\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-e25d391fe1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# we have a \"good\" classifier (according to GridSearchCV), how's it look\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best estimator found by grid search:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"i\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_status_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibsvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "tmp_vectors = train_data\n",
    "tmp_labels = train_labels\n",
    "\n",
    "print(\"Fitting the classifier to the training set\")\n",
    "\n",
    "param_grid = {'C': [0.01,0.1,1.0,10.0],\n",
    "              'gamma': [0.01,0.1,1.0,10.0],\n",
    "              'kernel': ['linear','rbf']}\n",
    "# make a classifier by searching over a classifier and the parameter grid\n",
    "clf = GridSearchCV(SVC(class_weight='balanced'), param_grid)\n",
    "\n",
    "# we have a \"good\" classifier (according to GridSearchCV), how's it look\n",
    "clf = clf.fit(tmp_vectors, tmp_labels)\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf.best_estimator_)\n",
    "print(\"Best parameters found by grid search:\")\n",
    "print(clf.best_params_)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Runtime\",end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The best for hyper-parameters are 0.01 for both C and gamma.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 (8 Points)\n",
    "Using your best-fit parameters, classify your test data and print off the confusion matrix. Note/calculate the Precision and Recall for your SVM model, as well as the overall accuracy.\n",
    "\n",
    "$\\mathrm{Accuracy} = \\frac{\\mathrm{Accurate~Predictions}}{\\mathrm{Total~Samples}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the classifier to the training set\n",
      "Predicting if it will \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.86      0.90       687\n",
      "           1       0.68      0.85      0.76       232\n",
      "\n",
      "    accuracy                           0.86       919\n",
      "   macro avg       0.81      0.86      0.83       919\n",
      "weighted avg       0.88      0.86      0.87       919\n",
      "\n",
      "The Accuracy is 0.8313384113166485\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp_vectors = train_data\n",
    "tmp_labels = train_labels\n",
    "\n",
    "print(\"Fitting the classifier to the training set\")\n",
    "param_grid = {'C': [0.01],'gamma': [0.01], 'kernel': ['linear']}\n",
    "\n",
    "clf = GridSearchCV(SVC(class_weight='balanced'), param_grid, n_jobs = -1)\n",
    "clf = clf.fit(tmp_vectors, tmp_labels)\n",
    "pred_x = test_data\n",
    "y_true = test_labels\n",
    "print(\"Predicting if it will \")\n",
    "pred_labels = clf.predict(pred_x)\n",
    "print(classification_report(y_true, pred_labels))\n",
    "ConfusionMatrixDisplay.from_estimator(clf, test_data, test_labels, display_labels = [True, False])\n",
    "\n",
    "prediction = 555+209\n",
    "total = 919\n",
    "Accuracy = prediction/total\n",
    "print(\"The Accuracy is\",Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[622  63]\n",
      " [ 61 173]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       685\n",
      "           1       0.73      0.74      0.74       234\n",
      "\n",
      "    accuracy                           0.87       919\n",
      "   macro avg       0.82      0.82      0.82       919\n",
      "weighted avg       0.87      0.87      0.87       919\n",
      "\n",
      "0.8650707290533188\n"
     ]
    }
   ],
   "source": [
    "#Write your code here\n",
    "pred_labels = grid_search.predict(test_data)\n",
    "\n",
    "print(confusion_matrix(true_labels, pred_labels))\n",
    "print(classification_report(true_labels, pred_labels))\n",
    "\n",
    "Acurracy = (622+173)/len(test_data)\n",
    "print(Acurracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation of Models\n",
    "\n",
    "Here we’re going to investigate how well our predictive models actually work.\n",
    "\n",
    "\n",
    "#### 5.1 (5 Points)\n",
    "\n",
    "Compare the accuracy of both of your predictive models (regression and SVM) to the baseline model from part 3. Do your predictive models do better than the baseline model? Is their performance relative to the baseline model what *you* would expect? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The baseline model accuracy was the lowest accuracy. The value was found to be 74.5%, this was the lowest accuracy. The SVM was found to have a higher accuracy of 83.1%. The accuracy for the regression model was found to be the most accurate at 86.5%. Both of the models created were found to be more accurate then the simple frequency model. I did expect this performance relative to the baseline model. Since the two models are Machine learning models and learning from the data how to predict accurate values. Therefore, it makes sense that the value would be quite a bit higher than the simple frequency prediction, where we simply predicted that it won't rain everyday since that is what happens majority of the time.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 (5 Points)\n",
    "\n",
    "Let’s test the robustness of your model. Before you do anything, you should record the precision, recall, and accuracy of your two predictive models (if you haven’t already). Once you’ve done that, go all the way back to part 1.4 and change the random seed for `train_test_split`. Using this new data split, rerun all of your code from parts 2 and 4. For each new random seed, record the precision, recall, and accuracy for both models (and write them, as well as the random seed, in the cell below!). Do this for 3-5 different random seeds. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regession Model: \n",
    "Initially: seed = 42, accuracy = 87%, precision = 0: 0.92, 1: 0.73, recall = 0: 0.90, 0: 0.76.\n",
    "\n",
    "Round 2: seed = 21, accuracy = 86%, precision = 0: 0.88, 1: 0.78, recall = 0: 0.94, 0: 0.60.\n",
    "\n",
    "Round 3: seed = 84, accuracy = 87%, precision = 0: 0.92, 1: 0.75, recall = 0: 0.92, 0: 0.75.\n",
    "\n",
    "Round 4: seed = 168, accuracy = 86%, precision = 0: 0.89, 1: 0.74, recall = 0: 0.93, 0: 0.65.\n",
    "\n",
    "\n",
    "SVM: \n",
    "Initially: seed = 42, accuracy = 83%, precision = 0: 0.96, 1: 0.62, recall = 0: 0.81, 0: 0.89.\n",
    "\n",
    "Round 2: seed = 21, accuracy = 86%, precision = 0: 0.88, 1: 0.78, recall = 0: 0.94, 0: 0.60.\n",
    "\n",
    "Round 3: seed = 84, accuracy = 87%, precision = 0: 0.92, 1: 0.75, recall = 0: 0.92, 0: 0.75.\n",
    "\n",
    "Round 4: seed = 168, accuracy = 86%, precision = 0: 0.89, 1: 0.74, recall = 0: 0.93, 0: 0.65."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 (5 Points)\n",
    "\n",
    "How much variation did you observe in the precision, recall, and accuracy in your models? After going through this exercise, how (if at all) does this change your response to part 5.1? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*There was very little variation in accuracy for all the different seeds. The accuracy stayed between 86% or 87% which is still more accurate than the SVM as well as the baseline case. The precision and recall varied a bit more, but not to an extreme amount that will affect the accuracy. Therefore I wouldn't change anything from my response in 5.1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 (5 Points)\n",
    "\n",
    "Finally, compare the performance of your regression and SVM models. Which, if any, performed better? Esxplain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The regression model is more accurate compared to the SVM they are both better than the baseline, but when compared to one another the regression comes out on top. Especially since the regression model values flucuated less when set at different seeds. Therefore making it a more consistent model.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### &#128721; STOP (3 Point)\n",
    "**Pause to commit your changes to your Git repository!**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository with a meaningful commit message.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations, you're done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#169; Copyright 2022,  Department of Computational Mathematics, Science and Engineering at Michigan State University"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
